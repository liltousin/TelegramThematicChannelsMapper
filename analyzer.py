import os

from dotenv import load_dotenv
from transformers import (XLMRobertaForSequenceClassification,
                          XLMRobertaTokenizer, pipeline)

# Ignore transformer warning


def initialize_classification_model():
    load_dotenv()
    hf_token = os.getenv("HF_TOKEN") or ""

    tokenizer = XLMRobertaTokenizer.from_pretrained("joeddav/xlm-roberta-large-xnli")
    model = XLMRobertaForSequenceClassification.from_pretrained(
        "joeddav/xlm-roberta-large-xnli"
    )

    return pipeline(
        "zero-shot-classification",
        model=model,
        tokenizer=tokenizer,
        token=hf_token,
    )


def classify_text_by_theme(classifier, text, theme_label):
    candidate_labels = [f"–Ω–µ {theme_label}", theme_label]

    result = classifier(text, candidate_labels)
    predicted_label = result["labels"][0]
    return predicted_label == theme_label, result["scores"][0]


if __name__ == "__main__":
    # pip install protobuf

    sequences_to_classify = [
        "üöÄ –ù–æ–≤–æ—Å—Ç–∏ –∏–∑ –º–∏—Ä–∞ –º–∞–π–Ω–∏–Ω–≥–∞! –°–µ–≥–æ–¥–Ω—è –æ–±—Å—É–∂–¥–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≤ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –¥–æ–±—ã—á–∏, –∞ —Ç–∞–∫–∂–µ –¥–µ–ª–∏–º—Å—è –æ–ø—ã—Ç–æ–º –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ –º–∞–π–Ω–∏–Ω–≥-—Ä–∏–≥–∞. üíªüõ†Ô∏è #–ú–∞–π–Ω–∏–Ω–≥ #–ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞",
        "‚õèÔ∏è –í —ç—Ç–æ—Ç –≤–µ—á–µ—Ä –æ–±—Å—É–¥–∏–º –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã –º–∞–π–Ω–∏–Ω–≥–∞ –Ω–æ–≤–æ–π –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã. –ö–∞–∫–∏–µ –∞–ª–≥–æ—Ä–∏—Ç–º—ã —Å—Ç–æ–∏—Ç —Ä–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∏ –∫–∞–∫ –≤—ã–±—Ä–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏–µ? –ü—Ä–∏—Ö–æ–¥–∏—Ç–µ –¥–µ–ª–∏—Ç—å—Å—è —Å–≤–æ–∏–º –æ–ø—ã—Ç–æ–º! ü§îüí° #–ú–∞–π–Ω–∏–Ω–≥–¢—Ä–µ–Ω–¥—ã #–ö—Ä–∏–ø—Ç–∞",
        "üî• –°–≤–µ–∂–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–∞–π–Ω–∏–Ω–≥–æ–≤–æ–≥–æ –ø—É–ª–∞! –°–µ–≥–æ–¥–Ω—è—à–Ω–∏–π –¥–µ–Ω—å –ø—Ä–∏–Ω–µ—Å –Ω–æ–≤—ã–µ —Ä–µ–∫–æ—Ä–¥—ã. –û–±—Å—É–¥–∏–º –ª—É—á—à–∏–µ –º–µ—Ç–æ–¥—ã –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ —Ö—ç—à—Ä–µ–π—Ç–∞ –∏ –∫–∞–∫ —É–≤–µ–ª–∏—á–∏—Ç—å –ø—Ä–∏–±—ã–ª—å–Ω–æ—Å—Ç—å –º–∞–π–Ω–∏–Ω–≥–∞. üí∞üìà #–ú–∞–π–Ω–∏–Ω–≥–ü—É–ª #–ú–∞–π–Ω–µ—Ä—ã",
        "üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –º–æ–º–µ–Ω—Ç: –∫–∞–∫ —É–ª—É—á—à–∏—Ç—å –æ—Ö–ª–∞–∂–¥–µ–Ω–∏–µ –º–∞–π–Ω–∏–Ω–≥-—Ñ–µ—Ä–º—ã? –û–±—Å—É–∂–¥–∞–µ–º –Ω–æ–≤—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏. –î–µ–ª–∏—Ç–µ—Å—å —Å–≤–æ–∏–º–∏ —Å–µ–∫—Ä–µ—Ç–∞–º–∏ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö! ‚ùÑÔ∏èüå°Ô∏è #–û—Ö–ª–∞–∂–¥–µ–Ω–∏–µ–§–µ—Ä–º—ã #–ú–∞–π–Ω–∏–Ω–≥–¢–µ—Ö–Ω–∏–∫–∞",
        "üí° –°–µ–≥–æ–¥–Ω—è –≤ —Ñ–æ–∫—É—Å–µ ‚Äî –º–∞–π–Ω–∏–Ω–≥ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç. –ì–¥–µ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –ø—Ä–æ–µ–∫—Ç—ã, –∏ –∫–∞–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã —Å—Ç–æ–∏—Ç —É—á–µ—Å—Ç—å –ø—Ä–∏ –≤—ã–±–æ—Ä–µ? –û–±—Å—É–¥–∏–º –≤–º–µ—Å—Ç–µ! üåêü§ë #–ê–ª—å—Ç–ú–∞–π–Ω–∏–Ω–≥ #–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏",
        ".",
    ]
    theme = "–º–∞–π–Ω–∏–Ω–≥"

    classifier_model = initialize_classification_model()

    for seq in sequences_to_classify:
        is_mining, score = classify_text_by_theme(classifier_model, seq, theme)
        print(f"\n\n–¢–µ–∫—Å—Ç –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ç–µ–º–µ '{theme}': {is_mining} score: {score}\n\n")
